\contentsline {section}{\numberline {1}Introduction}{3}{}%
\contentsline {subsection}{\numberline {1.1}Context and motivation}{3}{}%
\contentsline {subsection}{\numberline {1.2}Project objectives}{3}{}%
\contentsline {subsection}{\numberline {1.3}Working hypothesis: resilience of poisoned samples to misclassification}{4}{}%
\contentsline {subsection}{\numberline {1.4}Observations: Implications of the “Lottery Ticket Hypothesis” on Backdoor Resilience}{4}{}%
\contentsline {subsubsection}{\numberline {1.4.1}Resilience of Noise-Scattered Subnetworks}{5}{}%
\contentsline {subsubsection}{\numberline {1.4.2}Potential Implication for Poisoning Detection}{5}{}%
\contentsline {section}{\numberline {2}State of the art}{6}{}%
\contentsline {subsection}{\numberline {2.1}Data Poisoning and Backdoor Attacks in ML Models}{6}{}%
\contentsline {subsubsection}{\numberline {2.1.1}Clean-label attacks and feature-based backdoors}{6}{}%
\contentsline {subsection}{\numberline {2.2}Detection and mitigation techniques}{7}{}%
\contentsline {subsection}{\numberline {2.3}Sparsity and robustness of neural models}{7}{}%
\contentsline {section}{\numberline {3}Methodology}{8}{}%
\contentsline {subsection}{\numberline {3.1}Construction of the dataset}{8}{}%
\contentsline {subsubsection}{\numberline {3.1.1}Poisoned dataset}{8}{}%
\contentsline {subsubsection}{\numberline {3.1.2}Preprocessing and feature extraction}{8}{}%
\contentsline {subsection}{\numberline {3.2}Malware classifier architecture}{8}{}%
\contentsline {subsubsection}{\numberline {3.2.1}Neural networks used}{8}{}%
\contentsline {subsubsection}{\numberline {3.2.2}Evaluation Metrics}{8}{}%
\contentsline {paragraph}{Confusion Matrix Components}{9}{}%
\contentsline {paragraph}{Standard Classification Metrics}{9}{}%
\contentsline {paragraph}{Threshold-Independent Evaluation. }{9}{}%
\contentsline {subsubsection}{\numberline {3.2.3}Comparison with Baseline Defenses}{9}{}%
\contentsline {subsection}{\numberline {3.3}Introduction of noise and sparsification}{9}{}%
\contentsline {subsubsection}{\numberline {3.3.1}Adaptive disturbance of internal weights}{9}{}%
\contentsline {paragraph}{Automatic tuning algorithm}{9}{}%
\contentsline {subsubsection}{\numberline {3.3.2}Applying structural pruning techniques}{10}{}%
\contentsline {paragraph}{Detection via Weight Pruning}{10}{}%
\contentsline {paragraph}{Defense through Optimal Pruning}{10}{}%
\contentsline {paragraph}{Displaying results}{12}{}%
\contentsline {subsection}{\numberline {3.4}Dataset Analysis and Result Visualization}{12}{}%
\contentsline {subsubsection}{\numberline {3.4.1}Single-Run Evaluation Metrics}{12}{}%
\contentsline {paragraph}{Top Row: Performance Metrics. }{13}{}%
\contentsline {paragraph}{Bottom Row: Confusion Matrices. }{13}{}%
\contentsline {subsubsection}{\numberline {3.4.2}Other Tools}{13}{}%
\contentsline {section}{\numberline {4}Dataset Information}{16}{}%
\contentsline {subsection}{\numberline {4.1}EMBER Dataset Overview}{16}{}%
\contentsline {subsubsection}{\numberline {4.1.1}Dataset Structure}{16}{}%
\contentsline {subsubsection}{\numberline {4.1.2}Feature Categories}{16}{}%
\contentsline {subsection}{\numberline {4.2}Feature Quality Analysis}{17}{}%
\contentsline {subsection}{\numberline {4.3}Correlation Analysis}{17}{}%
\contentsline {subsection}{\numberline {4.4}Feature Selection Impact}{17}{}%
\contentsline {subsection}{\numberline {4.5}Feature Importance Analysis}{18}{}%
\contentsline {subsection}{\numberline {4.6}Feature Selection Pipeline}{19}{}%
\contentsline {section}{\numberline {5}Experiments}{21}{}%
\contentsline {subsection}{\numberline {5.1}Experimental Setup}{21}{}%
\contentsline {subsubsection}{\numberline {5.1.1}Test Procedures Summary}{21}{}%
\contentsline {subsection}{\numberline {5.2}Limitations of the experimental setup}{22}{}%
\contentsline {subsubsection}{\numberline {5.2.1}Data limitations}{22}{}%
\contentsline {subsubsection}{\numberline {5.2.2}Test limitations}{22}{}%
\contentsline {section}{\numberline {6}Results}{23}{}%
\contentsline {subsection}{\numberline {6.1}University cluster}{23}{}%
\contentsline {subsection}{\numberline {6.2}Model performance - Mac}{23}{}%
\contentsline {subsubsection}{\numberline {6.2.1}EMBER 2018 dataset}{23}{}%
\contentsline {subsubsection}{\numberline {6.2.2}Backdoor Attack Effects: The Superfeature Phenomenon}{25}{}%
\contentsline {subsubsection}{\numberline {6.2.3}Defense Strategy Effectiveness}{25}{}%
\contentsline {paragraph}{Isolation Forest.}{25}{}%
\contentsline {paragraph}{Weight Pruning.}{26}{}%
\contentsline {paragraph}{Gaussian Noise.}{26}{}%
\contentsline {paragraph}{Comparative Analysis.}{26}{}%
\contentsline {subsection}{\numberline {6.3}Model Performance - University Cluster}{27}{}%
\contentsline {subsubsection}{\numberline {6.3.1}Enhanced Computational Environment}{27}{}%
\contentsline {subsubsection}{\numberline {6.3.2}Backdoor Attack Effects: Divergent Performance Patterns}{28}{}%
\contentsline {subsubsection}{\numberline {6.3.3}Defense Strategy Effectiveness}{29}{}%
\contentsline {paragraph}{Isolation Forest.}{29}{}%
\contentsline {paragraph}{Weight Pruning.}{30}{}%
\contentsline {paragraph}{Gaussian Noise.}{30}{}%
\contentsline {paragraph}{Comparative Analysis}{31}{}%
\contentsline {subsection}{\numberline {6.4}Comparison of Results Across Computational Environments}{31}{}%
\contentsline {subsubsection}{\numberline {6.4.1}Divergent Attack Impact Patterns}{31}{}%
\contentsline {subsubsection}{\numberline {6.4.2}Consistent Defense Effectiveness Limits}{32}{}%
\contentsline {subsubsection}{\numberline {6.4.3}Computational Resource Implications}{32}{}%
